# Note:  This is an example config, see habitat_baselines/config/pointnav/ppo_pointnav.yaml
# for better hyperparameters for actual training

BASE_TASK_CONFIG_PATH: "configs/targetdriven_mp3d.yaml"
TRAINER_NAME: "custom-ppo"
ENV_NAME: "TargetDrivenEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ["disk", "tensorboard"]
TENSORBOARD_DIR: "./logs/tb-targetdriven"
VIDEO_DIR: "./logs/video-targetdriven"
# To evaluate on all episodes, set this to -1
TEST_EPISODE_COUNT: 2
EVAL_CKPT_PATH_DIR: "./ckpts/targetdriven"
NUM_PROCESSES: 2
SENSORS: ["RGB_SENSOR"]
CHECKPOINT_FOLDER: "./ckpts/targetdriven"
NUM_UPDATES: 10000000
LOG_INTERVAL: 10
CHECKPOINT_INTERVAL: 1000

RL:
  PPO:
    # ppo params
    clip_param: 0.1
    ppo_epoch: 4
    num_mini_batch: 1
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-5
    max_grad_norm: 0.5
    num_steps: 128
    hidden_size: 512
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: True
    use_linear_lr_decay: True
    reward_window_size: 50
    
    DDPPO:
    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: GLOO
    # Visual encoder backbone
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True
    # Whether or not to reset the critic linear layer
    reset_critic: True

    # Model parameters
    backbone: resnet18
    rnn_type: LSTM
    num_recurrent_layers: 2

    force_distributed: True
